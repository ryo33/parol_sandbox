// ---------------------------------------------------------
// This file was generated by parol.
// It is not intended for manual editing and changes will be
// lost after next build.
// ---------------------------------------------------------

use parol_runtime::id_tree::Tree;
use parol_runtime::lexer::{TokenStream, Tokenizer};
use parol_runtime::miette::Result;
#[allow(unused_imports)]
use parol_runtime::parser::{
    DFATransition, LLKParser, LookaheadDFA, ParseTreeType, ParseType, Production,
};
use std::cell::RefCell;
use std::path::Path;

use crate::parol_sandbox_grammar::ParolSandboxGrammar;
use crate::parol_sandbox_grammar_trait::ParolSandboxGrammarAuto;

use parol_runtime::lexer::tokenizer::{
    ERROR_TOKEN, NEW_LINE_TOKEN, UNMATCHABLE_TOKEN, WHITESPACE_TOKEN,
};

pub const TERMINALS: &[&str; 10] = &[
    /*  0 */ UNMATCHABLE_TOKEN,
    /*  1 */ UNMATCHABLE_TOKEN,
    /*  2 */ UNMATCHABLE_TOKEN,
    /*  3 */ UNMATCHABLE_TOKEN,
    /*  4 */ UNMATCHABLE_TOKEN,
    /*  5 */ r###"""###,
    /*  6 */ r###"a"###,
    /*  7 */ r###"b"###,
    /*  8 */ r###"c"###,
    /*  9 */ ERROR_TOKEN,
];

pub const TERMINAL_NAMES: &[&str; 10] = &[
    /*  0 */ "EndOfInput",
    /*  1 */ "Newline",
    /*  2 */ "Whitespace",
    /*  3 */ "LineComment",
    /*  4 */ "BlockComment",
    /*  5 */ "Quote",
    /*  6 */ "A",
    /*  7 */ "B",
    /*  8 */ "C",
    /*  9 */ "Error",
];

/* SCANNER_0: "INITIAL" */
const SCANNER_0: (&[&str; 5], &[usize; 4]) = (
    &[
        /*  0 */ UNMATCHABLE_TOKEN,
        /*  1 */ NEW_LINE_TOKEN,
        /*  2 */ WHITESPACE_TOKEN,
        /*  3 */ r###"(//.*(\r\n|\r|\n|$))"###,
        /*  4 */ UNMATCHABLE_TOKEN,
    ],
    &[
        5, /* Quote */
        6, /* A */
        7, /* B */
        8, /* C */
    ],
);

/* SCANNER_1: "String" */
const SCANNER_1: (&[&str; 5], &[usize; 0]) = (
    &[
        /*  0 */ UNMATCHABLE_TOKEN,
        /*  1 */ UNMATCHABLE_TOKEN,
        /*  2 */ UNMATCHABLE_TOKEN,
        /*  3 */ UNMATCHABLE_TOKEN,
        /*  4 */ UNMATCHABLE_TOKEN,
    ],
    &[],
);

const MAX_K: usize = 1;

pub const NON_TERMINALS: &[&str; 3] = &[
    /* 0 */ "ParolSandbox",
    /* 1 */ "ParolSandboxList",
    /* 2 */ "ParolSandboxListGroup",
];

pub const LOOKAHEAD_AUTOMATA: &[LookaheadDFA; 3] = &[
    /* 0 - "ParolSandbox" */
    LookaheadDFA {
        states: &[Some(0)],
        transitions: &[],
        k: 0,
    },
    /* 1 - "ParolSandboxList" */
    LookaheadDFA {
        states: &[None, Some(1), Some(5)],
        transitions: &[
            DFATransition(0, 5, 2),
            DFATransition(0, 6, 1),
            DFATransition(0, 7, 1),
            DFATransition(0, 8, 1),
        ],
        k: 1,
    },
    /* 2 - "ParolSandboxListGroup" */
    LookaheadDFA {
        states: &[None, Some(2), Some(3), Some(4)],
        transitions: &[
            DFATransition(0, 6, 1),
            DFATransition(0, 7, 2),
            DFATransition(0, 8, 3),
        ],
        k: 1,
    },
];

pub const PRODUCTIONS: &[Production; 6] = &[
    // 0 - ParolSandbox: /"/^ /* Clipped */ Push(1) ParolSandboxList /* Vec */ /"/^ /* Clipped */ Pop;
    Production {
        lhs: 0,
        production: &[
            ParseType::Pop,
            ParseType::T(5),
            ParseType::N(1),
            ParseType::Push(1),
            ParseType::T(5),
        ],
    },
    // 1 - ParolSandboxList: ParolSandboxListGroup ParolSandboxList;
    Production {
        lhs: 1,
        production: &[ParseType::N(1), ParseType::N(2)],
    },
    // 2 - ParolSandboxListGroup: /a/;
    Production {
        lhs: 2,
        production: &[ParseType::T(6)],
    },
    // 3 - ParolSandboxListGroup: /b/;
    Production {
        lhs: 2,
        production: &[ParseType::T(7)],
    },
    // 4 - ParolSandboxListGroup: /c/;
    Production {
        lhs: 2,
        production: &[ParseType::T(8)],
    },
    // 5 - ParolSandboxList: ;
    Production {
        lhs: 1,
        production: &[],
    },
];

parol_runtime::lazy_static::lazy_static! {
    static ref TOKENIZERS: Vec<(&'static str, Tokenizer)> = vec![
        ("INITIAL", Tokenizer::build(TERMINALS, SCANNER_0.0, SCANNER_0.1).unwrap()),
        ("String", Tokenizer::build(TERMINALS, SCANNER_1.0, SCANNER_1.1).unwrap()),

    ];
}

pub fn parse<'t, T>(
    input: &'t str,
    file_name: T,
    user_actions: &mut ParolSandboxGrammar<'t>,
) -> Result<Tree<ParseTreeType<'t>>>
where
    T: AsRef<Path>,
{
    let mut llk_parser = LLKParser::new(
        0,
        LOOKAHEAD_AUTOMATA,
        PRODUCTIONS,
        TERMINAL_NAMES,
        NON_TERMINALS,
    );
    let token_stream =
        RefCell::new(TokenStream::new(input, file_name, &TOKENIZERS, MAX_K).unwrap());
    // Initialize wrapper
    let mut user_actions = ParolSandboxGrammarAuto::new(user_actions);
    let result = llk_parser.parse(token_stream, &mut user_actions);
    match result {
        Ok(()) => Ok(llk_parser.parse_tree),
        Err(e) => Err(e),
    }
}
